{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.imgur.com/zRrFdsf.png\" width=\"700\"></center> \n",
    "\n",
    "_____\n",
    "\n",
    "<a id='home'></a>\n",
    "\n",
    "# Merging\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/CienciaDeDatosEspacial/code_and_data/blob/main/Merging_DFs.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging data sets need the following considerations:\n",
    "\n",
    "* Merging is done on two data frames.\n",
    "* You need a column in each data frame that share the same exact and unique values. The column names or titles need not be the same.\n",
    "* The merged table shows by default the mutual coincidences; but you can also request the values not matched, which will help you detect possible extra cleaning.\n",
    "* Pandas jargon uses a **left** and a **right** data frame: **left**.merge(**right**).\n",
    "\n",
    "At this stage, let me use other data frames we prepared previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "co2Link='https://github.com/CienciaDeDatosEspacial/dataSets/raw/main/co2.csv'\n",
    "\n",
    "forestLink='https://github.com/CienciaDeDatosEspacial/dataSets/raw/main/forestRev.csv'\n",
    "\n",
    "co2=pd.read_csv(co2Link)\n",
    "forest=pd.read_csv(forestLink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the amount of rows of each DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((218, 4), (204, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2.shape,forest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also keep in mind the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Country', 'ForestRev_gdp', 'ForestRev_date'], dtype='object'),\n",
       " Index(['name', 'co2', 'co2_date', 'region'], dtype='object'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.columns,co2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me show you some merge approaches, but I will only show the amount of columns produced:\n",
    "\n",
    "1. You keep only what is common in both key columns:\n",
    "\n",
    "This is the default. The final rows will be the ones where the key values in each data frame match exactly. In this case, your count of rows will be at most the amount of rows of the smallest data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many resulting rows after inner merging\n",
    "co2.merge(forest,how='inner',left_on='name',right_on='Country').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You keep all the keys from one data frame:\n",
    "\n",
    "The final rows will be all the rows from the dataframe (here from the _left_). If a key values does not find a match, the key value is kept, but the columns will have missing values. In this case, your count of rows will be equal to the amount of rows of the data frame to the left. You can also use **right** so the same logic applies to the data frame to the right.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many resulting rows after left merging\n",
    "co2.merge(forest,how='left',left_on='name',right_on='Country').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You keep all the rows from both data frames:\n",
    "\n",
    "In this case you will obtain all possible rows: the matched values, and the unmatched values from both data frames. You will also generate missing values. In this case, your count of rows will be at least the amount of rows of the data frame with the most rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many resulting rows after outer merging\n",
    "co2.merge(forest,how='outer',left_on='name',right_on='Country').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the different amount of rows? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANTARCTICA',\n",
       " 'BERMUDA',\n",
       " 'BRITISH VIRGIN ISLANDS',\n",
       " 'COOK ISLANDS',\n",
       " 'ERITREA',\n",
       " 'FALKLAND ISLANDS (ISLAS MALVINAS)',\n",
       " 'FRENCH POLYNESIA',\n",
       " 'GIBRALTAR',\n",
       " 'JERSEY',\n",
       " 'KOREA, NORTH',\n",
       " 'MONTSERRAT',\n",
       " 'NEW CALEDONIA',\n",
       " 'NIUE',\n",
       " 'SAINT HELENA, ASCENSION, AND TRISTAN DA CUNHA',\n",
       " 'SAINT PIERRE AND MIQUELON',\n",
       " 'SOMALIA',\n",
       " 'SOUTH AFRICA',\n",
       " 'SYRIA',\n",
       " 'TAIWAN',\n",
       " 'VENEZUELA',\n",
       " 'WAKE ISLAND'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(co2.name)-set(forest.Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANDORRA',\n",
       " 'CURACAO',\n",
       " 'ISLE OF MAN',\n",
       " 'LIECHTENSTEIN',\n",
       " 'MONACO',\n",
       " 'PALAU',\n",
       " 'SAN MARINO'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(forest.Country)-set(co2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the data is not available from every country. So, let's just continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2_date</th>\n",
       "      <th>region</th>\n",
       "      <th>Country</th>\n",
       "      <th>ForestRev_gdp</th>\n",
       "      <th>ForestRev_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHINA</td>\n",
       "      <td>1.077325e+10</td>\n",
       "      <td>2019</td>\n",
       "      <td>EAST AND SOUTHEAST ASIA</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>5.144361e+09</td>\n",
       "      <td>2019</td>\n",
       "      <td>NORTH AMERICA</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA</td>\n",
       "      <td>2.314738e+09</td>\n",
       "      <td>2019</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RUSSIA</td>\n",
       "      <td>1.848070e+09</td>\n",
       "      <td>2019</td>\n",
       "      <td>CENTRAL ASIA</td>\n",
       "      <td>RUSSIA</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JAPAN</td>\n",
       "      <td>1.103234e+09</td>\n",
       "      <td>2019</td>\n",
       "      <td>EAST AND SOUTHEAST ASIA</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>TONGA</td>\n",
       "      <td>1.710000e+05</td>\n",
       "      <td>2019</td>\n",
       "      <td>AUSTRALIA AND OCEANIA</td>\n",
       "      <td>TONGA</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>KIRIBATI</td>\n",
       "      <td>7.600000e+04</td>\n",
       "      <td>2019</td>\n",
       "      <td>AUSTRALIA AND OCEANIA</td>\n",
       "      <td>KIRIBATI</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>NAURU</td>\n",
       "      <td>6.600000e+04</td>\n",
       "      <td>2019</td>\n",
       "      <td>AUSTRALIA AND OCEANIA</td>\n",
       "      <td>NAURU</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>NORTHERN MARIANA ISLANDS</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2019</td>\n",
       "      <td>AUSTRALIA AND OCEANIA</td>\n",
       "      <td>NORTHERN MARIANA ISLANDS</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>TUVALU</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2019</td>\n",
       "      <td>AUSTRALIA AND OCEANIA</td>\n",
       "      <td>TUVALU</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name           co2  co2_date  \\\n",
       "0                       CHINA  1.077325e+10      2019   \n",
       "1               UNITED STATES  5.144361e+09      2019   \n",
       "2                       INDIA  2.314738e+09      2019   \n",
       "3                      RUSSIA  1.848070e+09      2019   \n",
       "4                       JAPAN  1.103234e+09      2019   \n",
       "..                        ...           ...       ...   \n",
       "192                     TONGA  1.710000e+05      2019   \n",
       "193                  KIRIBATI  7.600000e+04      2019   \n",
       "194                     NAURU  6.600000e+04      2019   \n",
       "195  NORTHERN MARIANA ISLANDS  0.000000e+00      2019   \n",
       "196                    TUVALU  0.000000e+00      2019   \n",
       "\n",
       "                      region                   Country  ForestRev_gdp  \\\n",
       "0    EAST AND SOUTHEAST ASIA                     CHINA           0.08   \n",
       "1              NORTH AMERICA             UNITED STATES           0.04   \n",
       "2                 SOUTH ASIA                     INDIA           0.14   \n",
       "3               CENTRAL ASIA                    RUSSIA           0.29   \n",
       "4    EAST AND SOUTHEAST ASIA                     JAPAN           0.02   \n",
       "..                       ...                       ...            ...   \n",
       "192    AUSTRALIA AND OCEANIA                     TONGA           0.03   \n",
       "193    AUSTRALIA AND OCEANIA                  KIRIBATI           0.04   \n",
       "194    AUSTRALIA AND OCEANIA                     NAURU           0.00   \n",
       "195    AUSTRALIA AND OCEANIA  NORTHERN MARIANA ISLANDS           0.00   \n",
       "196    AUSTRALIA AND OCEANIA                    TUVALU           0.00   \n",
       "\n",
       "     ForestRev_date  \n",
       "0              2018  \n",
       "1              2018  \n",
       "2              2018  \n",
       "3              2018  \n",
       "4              2018  \n",
       "..              ...  \n",
       "192            2018  \n",
       "193            2018  \n",
       "194            2018  \n",
       "195            2018  \n",
       "196            2018  \n",
       "\n",
       "[197 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the default is inner merge\n",
    "cia=co2.merge(forest,left_on='name',right_on='Country')\n",
    "cia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring back the data on fragility, but just for the year 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\fragility.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#read in:\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m FragilityAll\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfragility.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#subset\u001b[39;00m\n\u001b[0;32m      7\u001b[0m fragile2019\u001b[38;5;241m=\u001b[39mFragilityAll\u001b[38;5;241m.\u001b[39mloc[FragilityAll\u001b[38;5;241m.\u001b[39mYear\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2019\u001b[39m,:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SDS_20232_final1610\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SDS_20232_final1610\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SDS_20232_final1610\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SDS_20232_final1610\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\SDS_20232_final1610\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\fragility.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#read in:\n",
    "FragilityAll=pd.read_csv(os.path.join(\"data\",\"fragility.csv\"))\n",
    "\n",
    "#subset\n",
    "fragile2019=FragilityAll.loc[FragilityAll.Year==2019,:\"Total\"].copy()\n",
    "\n",
    "# see\n",
    "\n",
    "fragile2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will practice **fuzzy merging** now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries in 'cia' but NOT in 'fragile2019' \n",
    "OnlyCia=set(cia.Country)-set(fragile2019.Country)\n",
    "OnlyCia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countris in 'fragile2019' but NOT in 'cia' \n",
    "OnlyFragile=set(fragile2019.Country)-set(cia.Country)\n",
    "OnlyFragile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we should try to find the what countries in _OnlyFragile_ may match the ones in _OnlyCia_. We need to use the **fuzzy merge** approach (please install **thefuzz** if not previously installed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process as fz\n",
    "\n",
    "# take a country from OnlyFragile\n",
    "# look for a country in OnlyCia and return the most similar\n",
    "[(f,fz.extractOne(f, OnlyCia)) for f in sorted(OnlyFragile)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you have found _some_ good matches. Let's keep the best ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(f,fz.extractOne(f, OnlyCia)) for f in sorted(OnlyFragile)\n",
    " if fz.extractOne(f, OnlyCia)[1]>=87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have good matches, you have to create dictionary like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesFragile1={f:fz.extractOne(f, OnlyCia)[0] \n",
    "                 for f in sorted(OnlyFragile)\n",
    "                 if fz.extractOne(f, OnlyCia)[1] >=87}\n",
    "#dict of matches\n",
    "changesFragile1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use that dict for the replacements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragile2019.Country.replace(to_replace=changesFragile1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the countries in fragile2019 have more matches. \n",
    "\n",
    "This process can be done a few more times, and you can recover more rows for the merging process. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second try\n",
    "OnlyCia=set(cia.Country)-set(fragile2019.Country)\n",
    "OnlyFragile=set(fragile2019.Country)-set(cia.Country)\n",
    "[(f,fz.extractOne(f, OnlyCia)) for f in sorted(OnlyFragile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OnlyFragile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# second dict of changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# select a different threshold\u001b[39;00m\n\u001b[0;32m      3\u001b[0m changesFragile2\u001b[38;5;241m=\u001b[39m{f:fz\u001b[38;5;241m.\u001b[39mextractOne(f, OnlyCia)[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m----> 4\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(OnlyFragile)\n\u001b[0;32m      5\u001b[0m                  \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m74\u001b[39m\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39mfz\u001b[38;5;241m.\u001b[39mextractOne(f, OnlyCia)[\u001b[38;5;241m1\u001b[39m]}\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#dict of matches\u001b[39;00m\n\u001b[0;32m      8\u001b[0m changesFragile2\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OnlyFragile' is not defined"
     ]
    }
   ],
   "source": [
    "# second dict of changes\n",
    "# select a different threshold\n",
    "changesFragile2={f:fz.extractOne(f, OnlyCia)[0] \n",
    "                 for f in sorted(OnlyFragile)\n",
    "                 if 74<=fz.extractOne(f, OnlyCia)[1]}\n",
    "\n",
    "#dict of matches\n",
    "changesFragile2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fragile2019' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make the changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fragile2019\u001b[38;5;241m.\u001b[39mCountry\u001b[38;5;241m.\u001b[39mreplace(to_replace\u001b[38;5;241m=\u001b[39mchangesFragile2,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fragile2019' is not defined"
     ]
    }
   ],
   "source": [
    "# make the changes\n",
    "fragile2019.Country.replace(to_replace=changesFragile2,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fragile2019' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# third try\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m OnlyCia\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m(cia\u001b[38;5;241m.\u001b[39mCountry)\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mset\u001b[39m(fragile2019\u001b[38;5;241m.\u001b[39mCountry)\n\u001b[0;32m      3\u001b[0m OnlyFragile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mset\u001b[39m(fragile2019\u001b[38;5;241m.\u001b[39mCountry)\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mset\u001b[39m(cia\u001b[38;5;241m.\u001b[39mCountry)\n\u001b[0;32m      4\u001b[0m [(f,fz\u001b[38;5;241m.\u001b[39mextractOne(f, OnlyCia)) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(OnlyFragile)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fragile2019' is not defined"
     ]
    }
   ],
   "source": [
    "# third try\n",
    "OnlyCia=set(cia.Country)-set(fragile2019.Country)\n",
    "OnlyFragile=set(fragile2019.Country)-set(cia.Country)\n",
    "[(f,fz.extractOne(f, OnlyCia)) for f in sorted(OnlyFragile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third dict of changes\n",
    "# new threshold\n",
    "changesFragile3={f:fz.extractOne(f, OnlyCia)[0] \n",
    "                 for f in sorted(OnlyFragile)\n",
    "                 if 54==fz.extractOne(f, OnlyCia)[1]}\n",
    "\n",
    "#dict of matches\n",
    "changesFragile3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make changes\n",
    "fragile2019.Country.replace(to_replace=changesFragile3,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth try\n",
    "\n",
    "OnlyCia=set(cia.Country)-set(fragile2019.Country)\n",
    "OnlyFragile=set(fragile2019.Country)-set(cia.Country)\n",
    "[(f,fz.extractOne(f, OnlyCia)) for f in sorted(OnlyFragile)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth attempt did not offer good results. So we are ready:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragilecia=fragile2019.merge(cia) #merge on Country\n",
    "fragilecia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking:\n",
    "fragilecia.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging is a key process for producing analytics. So, it is always good to add some 'standard' information to avoid the need of fuzzy merging. See this data table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isoLink='https://github.com/CienciaDeDatosEspacial/dataSets/raw/main/isodata.csv'\n",
    "isoCodes=pd.read_csv(isoLink)\n",
    "isoCodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should add the **ISO** columns to our recent merged data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key columns are not spelled the same:\n",
    "isoCodes.Countryname=isoCodes.Countryname.str.upper()\n",
    "isoCodes.merge(fragilecia,left_on='Countryname',right_on='Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have lost several countries, then we redo the fuzzy merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyFrcia=set(fragilecia.Country)-set(isoCodes.Countryname)\n",
    "onlyISO=set(isoCodes.Countryname)-set(fragilecia.Country)\n",
    "\n",
    "[(f,fz.extractOne(f, onlyISO)) for f in sorted(onlyFrcia)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first change\n",
    "changesFrcia1={f:fz.extractOne(f, onlyISO)[0] \n",
    "                 for f in sorted(onlyFrcia)\n",
    "                 if fz.extractOne(f, onlyISO)[1] >=87}\n",
    "#dict of matches\n",
    "changesFrcia1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make changes\n",
    "fragilecia.Country.replace(to_replace=changesFrcia1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyFrcia=set(fragilecia.Country)-set(isoCodes.Countryname)\n",
    "onlyISO=set(isoCodes.Countryname)-set(fragilecia.Country)\n",
    "\n",
    "[(f,fz.extractOne(f, onlyISO)) for f in sorted(onlyFrcia)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second iteration gives weird results. Let's use a different function to get more than one result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyFrcia=set(fragilecia.Country)-set(isoCodes.Countryname)\n",
    "onlyISO=set(isoCodes.Countryname)-set(fragilecia.Country)\n",
    "\n",
    "[(f,fz.extract(f, onlyISO)) for f in sorted(onlyFrcia)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember you can use this for a particular case:\n",
    "isoCodes.loc[isoCodes.Countryname.str.contains('LAO')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, just prepare manual changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastChanges={'CONGO, REPUBLIC OF THE':'CONGO (THE)',\n",
    " 'KOREA, SOUTH':'KOREA (THE REPUBLIC OF)',\n",
    "'LAOS':\"LAO PEOPLE'S DEMOCRATIC REPUBLIC (THE)\"}\n",
    "\n",
    "fragilecia.Country.replace(to_replace=lastChanges,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragciaiso=isoCodes.merge(fragilecia,left_on='Countryname',right_on='Country')\n",
    "fragciaiso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragciaiso.drop(columns=['Country','name'],inplace=True)\n",
    "fragciaiso.rename(columns={'Countryname':\"Country\",'Year':'fragility_date','Total':'fragility'},inplace=True)\n",
    "fragciaiso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragciaiso.to_csv(os.path.join(\"data\",\"FragilityCia_isos.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
